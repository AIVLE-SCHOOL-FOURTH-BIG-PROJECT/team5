{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 23:17:13.849176: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-20 23:17:13.872725: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-20 23:17:13.872746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-20 23:17:13.873445: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 23:17:13.877419: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 23:17:14.298826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress most of the logs\n",
    "tf.get_logger().setLevel('WARNING')  # Adjust logging level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('images64.npy')\n",
    "y = np.load('styles64.npy')\n",
    "# X and y are now numpy arrays containing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Classic', 'Contemporary', 'Country', 'Minimalism', 'Modern',\n",
       "       'Unique', 'Urban'], dtype='<U12')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming y contains integer labels\n",
    "y = to_categorical(y, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n",
    "# Now proceed with the train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6970, 64, 64, 3) (871, 64, 64, 3) (872, 64, 64, 3)\n",
      "(6970, 7) (871, 7) (872, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Conv2D, AvgPool2D, Flatten, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 32)        1568      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 64, 64, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " average_pooling2d_12 (Aver  (None, 16, 16, 32)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 16)        8208      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 16, 16, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_13 (Aver  (None, 4, 4, 16)          0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 8)           2056      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 4, 4, 8)           32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 4, 4, 8)           0         \n",
      "                                                                 \n",
      " average_pooling2d_14 (Aver  (None, 1, 1, 8)           0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               1152      \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14623 (57.12 KB)\n",
      "Trainable params: 14255 (55.68 KB)\n",
      "Non-trainable params: 368 (1.44 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(X_train.shape[1:]),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Conv2D(filters=16, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Conv2D(filters=8, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(7),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=5,\n",
    "                              verbose=1,\n",
    "                              min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "start fitting\n",
      "Epoch 1/10000000\n",
      "218/218 [==============================] - 2s 4ms/step - loss: 1.1221 - accuracy: 0.6680 - val_loss: 1.3352 - val_accuracy: 0.7061 - lr: 0.0010\n",
      "Epoch 2/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.9581 - accuracy: 0.7036 - val_loss: 0.9719 - val_accuracy: 0.7049 - lr: 0.0010\n",
      "Epoch 3/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.9170 - accuracy: 0.7164 - val_loss: 0.9805 - val_accuracy: 0.7049 - lr: 0.0010\n",
      "Epoch 4/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.8811 - accuracy: 0.7209 - val_loss: 1.2178 - val_accuracy: 0.5821 - lr: 0.0010\n",
      "Epoch 5/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.8485 - accuracy: 0.7314 - val_loss: 1.0074 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 6/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.8294 - accuracy: 0.7406 - val_loss: 1.1621 - val_accuracy: 0.6958 - lr: 0.0010\n",
      "Epoch 7/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.8123 - accuracy: 0.7442 - val_loss: 1.1723 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Epoch 8/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.7840 - accuracy: 0.7534 - val_loss: 0.8226 - val_accuracy: 0.7187 - lr: 0.0010\n",
      "Epoch 9/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.7658 - accuracy: 0.7588 - val_loss: 0.8087 - val_accuracy: 0.7268 - lr: 0.0010\n",
      "Epoch 10/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.7511 - accuracy: 0.7590 - val_loss: 1.2683 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 11/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.7393 - accuracy: 0.7644 - val_loss: 0.8499 - val_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 12/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.7106 - accuracy: 0.7712 - val_loss: 0.8776 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 13/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6994 - accuracy: 0.7789 - val_loss: 0.8247 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 14/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.7789 - val_loss: 0.8775 - val_accuracy: 0.7382 - lr: 0.0010\n",
      "Epoch 15/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6787 - accuracy: 0.7802 - val_loss: 0.8961 - val_accuracy: 0.7371 - lr: 0.0010\n",
      "Epoch 16/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6631 - accuracy: 0.7825 - val_loss: 1.0093 - val_accuracy: 0.6085 - lr: 0.0010\n",
      "Epoch 17/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.7805 - val_loss: 0.9098 - val_accuracy: 0.6739 - lr: 0.0010\n",
      "Epoch 18/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6515 - accuracy: 0.7872 - val_loss: 0.7557 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Epoch 19/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.7905 - val_loss: 0.7399 - val_accuracy: 0.7876 - lr: 0.0010\n",
      "Epoch 20/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.7912 - val_loss: 0.9167 - val_accuracy: 0.7256 - lr: 0.0010\n",
      "Epoch 21/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6070 - accuracy: 0.7970 - val_loss: 0.8601 - val_accuracy: 0.7727 - lr: 0.0010\n",
      "Epoch 22/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6060 - accuracy: 0.7948 - val_loss: 0.7862 - val_accuracy: 0.7658 - lr: 0.0010\n",
      "Epoch 23/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.8039 - val_loss: 0.8441 - val_accuracy: 0.7497 - lr: 0.0010\n",
      "Epoch 24/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.7993 - val_loss: 0.8655 - val_accuracy: 0.7669 - lr: 0.0010\n",
      "Epoch 25/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5804 - accuracy: 0.8043 - val_loss: 0.8831 - val_accuracy: 0.7325 - lr: 0.0010\n",
      "Epoch 26/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5639 - accuracy: 0.8050 - val_loss: 0.8497 - val_accuracy: 0.7245 - lr: 0.0010\n",
      "Epoch 27/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5553 - accuracy: 0.8165 - val_loss: 0.7245 - val_accuracy: 0.7899 - lr: 0.0010\n",
      "Epoch 28/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5558 - accuracy: 0.8113 - val_loss: 1.1862 - val_accuracy: 0.6774 - lr: 0.0010\n",
      "Epoch 29/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.8123 - val_loss: 0.9407 - val_accuracy: 0.7589 - lr: 0.0010\n",
      "Epoch 30/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.8139 - val_loss: 0.9858 - val_accuracy: 0.7532 - lr: 0.0010\n",
      "Epoch 31/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5385 - accuracy: 0.8194 - val_loss: 1.0338 - val_accuracy: 0.7245 - lr: 0.0010\n",
      "Epoch 32/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.8222 - val_loss: 0.8230 - val_accuracy: 0.7830 - lr: 0.0010\n",
      "Epoch 33/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.8244 - val_loss: 0.8885 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Epoch 34/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.8231 - val_loss: 0.7576 - val_accuracy: 0.7830 - lr: 0.0010\n",
      "Epoch 35/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8326 - val_loss: 0.8039 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Epoch 36/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8316 - val_loss: 0.7095 - val_accuracy: 0.8025 - lr: 0.0010\n",
      "Epoch 37/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.8369 - val_loss: 1.5916 - val_accuracy: 0.6005 - lr: 0.0010\n",
      "Epoch 38/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4780 - accuracy: 0.8377 - val_loss: 0.7176 - val_accuracy: 0.7658 - lr: 0.0010\n",
      "Epoch 39/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8311 - val_loss: 0.8058 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Epoch 40/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.8387 - val_loss: 0.9133 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Epoch 41/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.8379 - val_loss: 0.9818 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Epoch 42/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8453 - val_loss: 0.8570 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Epoch 43/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4584 - accuracy: 0.8426 - val_loss: 0.7055 - val_accuracy: 0.7968 - lr: 0.0010\n",
      "Epoch 44/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.8459 - val_loss: 1.0183 - val_accuracy: 0.7589 - lr: 0.0010\n",
      "Epoch 45/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.8406 - val_loss: 0.6761 - val_accuracy: 0.8002 - lr: 0.0010\n",
      "Epoch 46/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8449 - val_loss: 0.8506 - val_accuracy: 0.7933 - lr: 0.0010\n",
      "Epoch 47/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4403 - accuracy: 0.8475 - val_loss: 0.8946 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 48/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4426 - accuracy: 0.8443 - val_loss: 0.6785 - val_accuracy: 0.8002 - lr: 0.0010\n",
      "Epoch 49/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4384 - accuracy: 0.8518 - val_loss: 0.8877 - val_accuracy: 0.7497 - lr: 0.0010\n",
      "Epoch 50/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4298 - accuracy: 0.8439 - val_loss: 1.0520 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 51/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8514 - val_loss: 0.7568 - val_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 52/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.8597 - val_loss: 1.0249 - val_accuracy: 0.7245 - lr: 0.0010\n",
      "Epoch 53/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8476 - val_loss: 0.8019 - val_accuracy: 0.8037 - lr: 0.0010\n",
      "Epoch 54/10000000\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8572 - val_loss: 0.9765 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 55/10000000\n",
      "210/218 [===========================>..] - ETA: 0s - loss: 0.4128 - accuracy: 0.8521Restoring model weights from the end of the best epoch: 45.\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.8531 - val_loss: 1.1766 - val_accuracy: 0.6739 - lr: 0.0010\n",
      "Epoch 55: early stopping\n",
      "fitting done\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('start fitting')\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10000000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print('fitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 993us/step\n",
      "[1.3711634e-03 7.0549240e-03 7.3964198e-05 1.2461369e-05 9.9145377e-01\n",
      " 2.9698979e-08 3.3737851e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 4, 4, 0, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[0])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7958715596330275\n",
      "Confusion Matrix:\n",
      " [[ 49   2   1   3  55   0   0]\n",
      " [  2  20   3   0  39   0   0]\n",
      " [  5   3  22   0  14   0   0]\n",
      " [  1   2   1   5   5   0   0]\n",
      " [ 18  12   4   1 579   0   1]\n",
      " [  1   0   0   0   1   3   0]\n",
      " [  2   0   0   0   2   0  16]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.45      0.52       110\n",
      "           1       0.51      0.31      0.39        64\n",
      "           2       0.71      0.50      0.59        44\n",
      "           3       0.56      0.36      0.43        14\n",
      "           4       0.83      0.94      0.88       615\n",
      "           5       1.00      0.60      0.75         5\n",
      "           6       0.94      0.80      0.86        20\n",
      "\n",
      "    accuracy                           0.80       872\n",
      "   macro avg       0.74      0.57      0.63       872\n",
      "weighted avg       0.78      0.80      0.78       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if y_test.ndim > 1:  # Check if y_test is one-hot encoded\n",
    "    y_test_int_labels = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_int_labels = y_test  # y_test is already in integer label format\n",
    "\n",
    "# Now calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_int_labels, y_pred_labels))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_int_labels, y_pred_labels))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_int_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one image to get the input shape\n",
    "with h5py.File('image.h5', 'r') as h5file:\n",
    "    one_file = h5file['images'][0:1]  # Load the first image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "y = np.load('styles.npy', allow_pickle=True)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8713,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
