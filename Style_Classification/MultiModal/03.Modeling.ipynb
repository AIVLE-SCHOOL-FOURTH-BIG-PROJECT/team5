{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15224/2838925515.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X = torch.load('torch_img_text.pt')\n",
    "y = np.load('torch_styles.npy', allow_pickle=True)\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder and return encoded labels\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = 7  # As there are 7 unique labels (0 to 6)\n",
    "y = torch.nn.functional.one_hot(y_tensor, num_classes=num_classes)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11688, 2048]), torch.Size([11688, 7]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # No activation here; softmax will be applied during inference\n",
    "        return x\n",
    "\n",
    "# Instantiate the model with input size 2048\n",
    "input_size = 2048\n",
    "model = SimpleNN(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.Inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print('Early stopping triggered')\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize EarlyStopping object\n",
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [100/147], Loss: 1.24\n",
      "Validation Loss: 1.1109, Accuracy: 4.79%\n",
      "Epoch [2/1000], Step [100/147], Loss: 1.09\n",
      "Validation Loss: 1.0842, Accuracy: 0.09%\n",
      "Epoch [3/1000], Step [100/147], Loss: 1.04\n",
      "Validation Loss: 1.0613, Accuracy: 4.79%\n",
      "Epoch [4/1000], Step [100/147], Loss: 1.11\n",
      "Validation Loss: 1.0673, Accuracy: 7.01%\n",
      "Epoch [5/1000], Step [100/147], Loss: 0.98\n",
      "Validation Loss: 1.0668, Accuracy: 4.70%\n",
      "Epoch [6/1000], Step [100/147], Loss: 1.09\n",
      "Validation Loss: 1.0031, Accuracy: 7.70%\n",
      "Epoch [7/1000], Step [100/147], Loss: 0.82\n",
      "Validation Loss: 1.0632, Accuracy: 10.78%\n",
      "Epoch [8/1000], Step [100/147], Loss: 0.82\n",
      "Validation Loss: 1.0050, Accuracy: 10.78%\n",
      "Epoch [9/1000], Step [100/147], Loss: 0.84\n",
      "Validation Loss: 1.0878, Accuracy: 8.04%\n",
      "Epoch [10/1000], Step [100/147], Loss: 0.72\n",
      "Validation Loss: 0.9545, Accuracy: 10.78%\n",
      "Epoch [11/1000], Step [100/147], Loss: 0.88\n",
      "Validation Loss: 0.9370, Accuracy: 16.00%\n",
      "Epoch [12/1000], Step [100/147], Loss: 0.95\n",
      "Validation Loss: 0.9348, Accuracy: 18.14%\n",
      "Epoch [13/1000], Step [100/147], Loss: 0.60\n",
      "Validation Loss: 0.9320, Accuracy: 14.03%\n",
      "Epoch [14/1000], Step [100/147], Loss: 0.76\n",
      "Validation Loss: 0.8838, Accuracy: 27.37%\n",
      "Epoch [15/1000], Step [100/147], Loss: 0.89\n",
      "Validation Loss: 0.8719, Accuracy: 22.16%\n",
      "Epoch [16/1000], Step [100/147], Loss: 0.82\n",
      "Validation Loss: 0.9042, Accuracy: 24.21%\n",
      "Epoch [17/1000], Step [100/147], Loss: 0.88\n",
      "Validation Loss: 0.9942, Accuracy: 25.15%\n",
      "Epoch [18/1000], Step [100/147], Loss: 0.63\n",
      "Validation Loss: 0.8733, Accuracy: 26.01%\n",
      "Epoch [19/1000], Step [100/147], Loss: 0.82\n",
      "Validation Loss: 1.0772, Accuracy: 14.29%\n",
      "Epoch [20/1000], Step [100/147], Loss: 0.89\n",
      "Validation Loss: 0.8840, Accuracy: 26.52%\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create TensorDatasets for training and validation\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.2f}')\n",
    "\n",
    "    # Validation of the model\n",
    "    model.eval()  # it will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            # loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        # Early Stopping check\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8519, Test Accuracy: 17.02%\n"
     ]
    }
   ],
   "source": [
    "# Create TensorDataset for the test set\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss if you want to report test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 0)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(4096 , 128)\n",
    "        self.fc2 = nn.Linear(128, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # Flatten the dimensions for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [100/147], Loss: 0.91\n",
      "Validation Loss: 1.1208, Accuracy: 0.09%\n",
      "Epoch [2/1000], Step [100/147], Loss: 0.89\n",
      "Validation Loss: 1.0756, Accuracy: 4.88%\n",
      "Epoch [3/1000], Step [100/147], Loss: 1.11\n",
      "Validation Loss: 1.0086, Accuracy: 9.50%\n",
      "Epoch [4/1000], Step [100/147], Loss: 0.83\n",
      "Validation Loss: 0.9487, Accuracy: 9.41%\n",
      "Epoch [5/1000], Step [100/147], Loss: 0.62\n",
      "Validation Loss: 0.8940, Accuracy: 9.50%\n",
      "Epoch [6/1000], Step [100/147], Loss: 0.88\n",
      "Validation Loss: 0.8407, Accuracy: 16.77%\n",
      "Epoch [7/1000], Step [100/147], Loss: 0.62\n",
      "Validation Loss: 0.8203, Accuracy: 9.58%\n",
      "Epoch [8/1000], Step [100/147], Loss: 0.74\n",
      "Validation Loss: 0.7961, Accuracy: 14.80%\n",
      "Epoch [9/1000], Step [100/147], Loss: 0.71\n",
      "Validation Loss: 0.8079, Accuracy: 16.94%\n",
      "Epoch [10/1000], Step [100/147], Loss: 0.62\n",
      "Validation Loss: 0.7702, Accuracy: 14.46%\n",
      "Epoch [11/1000], Step [100/147], Loss: 0.50\n",
      "Validation Loss: 0.7544, Accuracy: 14.46%\n",
      "Epoch [12/1000], Step [100/147], Loss: 0.45\n",
      "Validation Loss: 0.7414, Accuracy: 14.80%\n",
      "Epoch [13/1000], Step [100/147], Loss: 0.71\n",
      "Validation Loss: 0.7678, Accuracy: 15.06%\n",
      "Epoch [14/1000], Step [100/147], Loss: 0.39\n",
      "Validation Loss: 0.7190, Accuracy: 24.04%\n",
      "Epoch [15/1000], Step [100/147], Loss: 0.29\n",
      "Validation Loss: 0.7209, Accuracy: 17.88%\n",
      "Epoch [16/1000], Step [100/147], Loss: 0.34\n",
      "Validation Loss: 0.8272, Accuracy: 15.40%\n",
      "Epoch [17/1000], Step [100/147], Loss: 0.28\n",
      "Validation Loss: 0.7507, Accuracy: 20.27%\n",
      "Epoch [18/1000], Step [100/147], Loss: 0.43\n",
      "Validation Loss: 0.9397, Accuracy: 22.41%\n",
      "Epoch [19/1000], Step [100/147], Loss: 0.22\n",
      "Validation Loss: 0.8159, Accuracy: 22.75%\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the CNN model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# EarlyStopping class as defined previously\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "       \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Reshape inputs if necessary\n",
    "        inputs = inputs.view(-1, 2, 32, 32)  # Adjust this to match your data\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.2f}')\n",
    "\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # Reshape inputs if necessary\n",
    "            inputs = inputs.view(-1, 2, 32, 32)  # Adjust this to match your data\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Early Stopping check\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7391, Test Accuracy: 14.63%\n"
     ]
    }
   ],
   "source": [
    "# Create TensorDataset for the test set\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.view(-1, 2, 32, 32)  # Adjust this to match your data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss if you want to report test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 0)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
