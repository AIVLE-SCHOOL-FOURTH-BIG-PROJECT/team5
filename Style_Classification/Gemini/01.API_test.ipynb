{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Used to securely store your API key\n",
    "# from google.colab import userdata\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "GOOGLE_API_KEY='AIzaSyAcwO2-b21bMnreTdjNlnnVJsmrGJVv0To'\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.31 ms, sys: 4.98 ms, total: 10.3 ms\n",
      "Wall time: 6.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"model = genai.GenerativeModel('gemini-pro-vision')\\nresponse = model.generate_content(img)\\n\\\n",
    "    to_markdown(response.text)\\nthis is my code. but i got this error message.\\n\\\n",
    "    TypeError: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\\n\\\n",
    "    Got a: <class 'PIL.JpegImagePlugin.JpegImageFile'>\\n\\\n",
    "    Value: <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1500x1482 at 0x7F1EA599B390>\"\n",
    "text2 = \"to_markdown(response.text)\\n\\\n",
    "    this is my code. in VSCode.\\n\\\n",
    "    but i get cropped output which is not scrollable. can you help me with VSCode Markdown settings?\"\n",
    "response = model.generate_content(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> 1. **Enable Word Wrap**:\n",
       "> \n",
       ">  - Open VSCode's **Settings** (Ctrl/Cmd + ,).\n",
       ">  - Search for \"**editor.wordWrap**\".\n",
       ">  - Set the value to `\"on\"`.\n",
       ">  - This will ensure that long lines of text wrap within the editor's width, making it easier to read.\n",
       "> \n",
       "> \n",
       "> 2. **Increase the Font Size**:\n",
       "> \n",
       ">  - Open **Settings** again and search for \"**editor.fontSize**\".\n",
       ">  - Adjust the font size to a value that is comfortable for you to read. A larger font size will give you more vertical space to view your Markdown content.\n",
       "> \n",
       "> \n",
       "> 3. **Use a Monospaced Font**:\n",
       "> \n",
       ">  - Monospaced fonts, such as \"Consolas\" or \"Courier New\", have characters that all take up the same amount of horizontal space. This can improve the readability of Markdown code and text.\n",
       ">  - To change the font, search for \"**editor.fontFamily**\" in **Settings**.\n",
       ">  - Select a monospaced font from the list of available fonts.\n",
       "> \n",
       "> \n",
       "> 4. **Disable Line Numbers**:\n",
       "> \n",
       ">  - Line numbers can take up valuable vertical space, especially if you have a lot of lines of code or text.\n",
       ">  - To disable line numbers, search for \"**editor.lineNumbers**\" in **Settings**.\n",
       ">  - Set the value to `\"off\"`.\n",
       "> \n",
       "> \n",
       "> 5. **Use a Markdown Preview Extension**:\n",
       "> \n",
       ">  - There are several Markdown preview extensions available for VSCode that can provide a more visually appealing and interactive preview of your Markdown content.\n",
       ">  - Some popular Markdown preview extensions include:\n",
       ">    - Markdown Preview Enhanced\n",
       ">    - Markdown All in One\n",
       ">    - Markdown Monster\n",
       ">  - Install one of these extensions and follow the extension's instructions to enable the Markdown preview.\n",
       "> \n",
       "> \n",
       "> 6. **Use a Markdown Linter**:\n",
       "> \n",
       ">  - A Markdown linter can help you identify and fix common Markdown formatting errors. This can make your Markdown content more consistent and easier to read.\n",
       ">  - Some popular Markdown linters for VSCode include:\n",
       ">    - Markdownlint\n",
       ">    - Markdown Linter\n",
       ">    - Vale\n",
       ">  - Install one of these linters and follow the extension's instructions to enable it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 0\n",
       "content {\n",
       "  parts {\n",
       "    text: \"There is no one definitive answer to the question of the meaning of life. Different people have different beliefs and values, and what is meaningful to one person may not be meaningful to another. Some people believe that the meaning of life is to find happiness, while others believe that it is to make a difference in the world. Some people believe that the meaning of life is to connect with others, while others believe that it is to find personal fulfillment. Ultimately, the meaning of life is a personal question that each individual must answer for themselves.\\n\\nSome common themes that people find meaningful in their lives include:\\n\\n* **Relationships:** Many people find meaning in their relationships with others, such as their family, friends, and romantic partners. These relationships can provide love, support, and a sense of belonging.\\n* **Work:** Many people find meaning in their work. This can be especially true for people who have jobs that they are passionate about and that allow them to make a difference in the world.\\n* **Personal growth:** Some people find meaning in personal growth and development. This can include learning new things, overcoming challenges, and becoming a better person.\\n* **Helping others:** Many people find meaning in helping others. This can be done through volunteering, donating to charity, or simply being kind and compassionate to others.\\n* **Spirituality:** Some people find meaning in spirituality or religion. This can provide a sense of purpose and connection to something greater than oneself.\\n\\nOf course, there are many other things that people can find meaningful in their lives. The key is to find what is meaningful to you and to live your life accordingly.\\n\\nHere are some additional thoughts on the meaning of life:\\n\\n* **The meaning of life is not something that is fixed or unchanging.** It can change over time as you grow and change.\\n* **There is no one right way to live your life.** What is meaningful to one person may not be meaningful to another.\\n* **The meaning of life is not something that you can achieve once and for all.** It is an ongoing journey that continues throughout your life.\\n* **The meaning of life is not something that you can find by yourself.** It is something that you create through your actions and choices.\"\n",
       "  }\n",
       "  role: \"model\"\n",
       "}\n",
       "finish_reason: STOP\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load the image from a file using PIL\n",
    "image_path = '/home/all/imgs/Sleeper_Sofas/ACMEASELinenFabricFutonSofaBedwithAdjustableBackrestsTuftedSleeperCouchwithConvertibleArmrestExtendableLoveseatSofawithPillowsforLivingRoomBedroomBeige.jpg' # ensure this path is correct\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Convert the PIL.JpegImageFile object to a Blob\n",
    "blob = io.BytesIO()\n",
    "img.save(blob, format='JPEG')\n",
    "\n",
    "# Reset the file pointer to the beginning of the stream\n",
    "blob.seek(0)\n",
    "\n",
    "# Reload the image from the blob\n",
    "img = Image.open(blob)\n",
    "\n",
    "# To display or use the image, continue from here\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class 'PIL.JpegImagePlugin.JpegImageFile'>\nValue: <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1500x1482 at 0x7F1E8F91CC10>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(img)\n\u001b[1;32m      3\u001b[0m to_markdown(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/generative_models.py:234\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@string_utils\u001b[39m\u001b[38;5;241m.\u001b[39mset_doc(_GENERATE_CONTENT_DOC)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_content\u001b[39m(\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    233\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse:\n\u001b[0;32m--> 234\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    235\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    236\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    237\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_default_generative_client()\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/generative_models.py:204\u001b[0m, in \u001b[0;36mGenerativeModel._prepare_request\u001b[0;34m(self, contents, generation_config, safety_settings, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 204\u001b[0m contents \u001b[38;5;241m=\u001b[39m content_types\u001b[38;5;241m.\u001b[39mto_contents(contents)\n\u001b[1;32m    206\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m generation_types\u001b[38;5;241m.\u001b[39mto_generation_config_dict(generation_config)\n\u001b[1;32m    207\u001b[0m merged_gc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generation_config\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/types/content_types.py:239\u001b[0m, in \u001b[0;36mto_contents\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# If you get a TypeError here it's probably because that was a list\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;66;03m# of parts, not a list of contents, so fall back to `to_content`.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m contents \u001b[38;5;241m=\u001b[39m [to_content(contents)]\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/types/content_types.py:205\u001b[0m, in \u001b[0;36mto_content\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glm\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[to_part(part) \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m content])\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# Maybe this is a Part?\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glm\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[to_part(content)])\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/types/content_types.py:172\u001b[0m, in \u001b[0;36mto_part\u001b[0;34m(part)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glm\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39mpart)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# Maybe it can be turned into a blob?\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glm\u001b[38;5;241m.\u001b[39mPart(inline_data\u001b[38;5;241m=\u001b[39mto_blob(part))\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.11/site-packages/google/generativeai/types/content_types.py:141\u001b[0m, in \u001b[0;36mto_blob\u001b[0;34m(blob)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blob, Mapping):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not recognize the intended type of the `dict`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA content should have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create `Blob`, expected `Blob`, `dict` or an `Image` type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(`PIL.Image.Image` or `IPython.display.Image`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(blob)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class 'PIL.JpegImagePlugin.JpegImageFile'>\nValue: <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1500x1482 at 0x7F1E8F91CC10>"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(img)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
