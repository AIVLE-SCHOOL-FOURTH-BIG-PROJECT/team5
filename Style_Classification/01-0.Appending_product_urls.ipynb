{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os\n",
    "from urllib.parse import urlparse, unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove metacharacters from title\n",
    "def processed_title(text):\n",
    "    return re.sub(r'\\W+', ' ', text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of keywords from title.\n",
    "def extract_keywords(title):\n",
    "    # This function should be improved with a better keyword extraction algorithm\n",
    "    return title.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match title and url, return score\n",
    "def match_url(title_keywords, url):\n",
    "    parsed_url = urlparse(url)\n",
    "    url_path = unquote(parsed_url.path + parsed_url.query)\n",
    "    url_keywords = re.findall(r'\\b\\w+\\b', url_path)\n",
    "    score = sum(keyword in url_keywords for keyword in title_keywords)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through urls, find best url for the title\n",
    "def find_best_url_match(title, urls_df):\n",
    "    title_keywords = extract_keywords(processed_title(title))\n",
    "    best_score = 0\n",
    "    best_url = None\n",
    "    for url in urls_df['Product URL']:\n",
    "        score = match_url(title_keywords, url)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_url = url\n",
    "    return best_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Sectional_Sofas', 'Sleeper_Sofas', 'Reclining_Sofas', 'LoveSeats', 'Futons', 'Settles', 'Convertibles', \n",
    "         'Accent_Chairs', 'Coffee_Tables', 'TV_Stands', 'End_Tables', 'Console_Tables', 'Ottomans', 'Living_Room_Sets', \n",
    "         'Decorative_Pillows', 'Throw_Blankets', 'Area_Rugs', 'Wall_Arts', 'Table_Lamps', 'Floor_Lamps', \n",
    "         'Pendants_and_Chandeliers', 'Sconces', 'Baskets_and_Storage', 'Candles', 'Live_Plants', 'Artificial_Plants', \n",
    "         'Planters', 'Decorative_Accessories', 'Window_Coverings', 'Decorative_Mirrors', 'Dining_Sets', \n",
    "         'Dining_Tables', 'Dining_Chairs', 'Bar_Stools', 'Kitchen_Islands', 'Buffets_and_Sideboards', 'China_Cabinets', \n",
    "         'Bakers_Recks', 'Bedroom_Sets', 'Mattresses', 'Nightstands', 'Dressers', 'Beds', 'Bedframes', 'Bases', 'Vanities', \n",
    "         'Entryway_Furnitures', 'Desks', 'Desk_Chairs', 'Bookcases', \n",
    "         'File_Cabinets', 'Computer_Armoires', 'Drafting_Tables', 'Cabinets', 'Furniture_Sets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_path = '/home/all/product_infos/'\n",
    "urls_path = '/home/all/product_urls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Product URL' column already exists in /home/all/product_infos/Sectional_Sofas_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Sleeper_Sofas_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Reclining_Sofas_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/LoveSeats_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Decorative_Pillows_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Throw_Blankets_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Table_Lamps_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Candles_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Dining_Chairs_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Bar_Stools_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Kitchen_Islands_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Buffets_and_Sideboards_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/China_Cabinets_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Bakers_Recks_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Bedroom_Sets_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Mattresses_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Nightstands_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Dressers_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Beds_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Bedframes_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Bases_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Vanities_product_infos.csv. Skipping.\n",
      "'Product URL' column already exists in /home/all/product_infos/Desks_product_infos.csv. Skipping.\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "        infos_file = os.path.join(infos_path, f'{name}_product_infos.csv')\n",
    "        urls_file = os.path.join(urls_path, f'{name}_product_urls.csv')\n",
    "\n",
    "        if os.path.exists(infos_file) and os.path.exists(urls_file):\n",
    "            infos_csv = pd.read_csv(infos_file)\n",
    "            urls_csv = pd.read_csv(urls_file)\n",
    "            \n",
    "            # Check if 'Product URL' column already exists\n",
    "            if 'Product URL' in infos_csv.columns:\n",
    "                print(f\"'Product URL' column already exists in {infos_file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Apply the function\n",
    "            print(f'Processing with {infos_file}')\n",
    "            infos_csv['Product URL'] = infos_csv['Title'].apply(lambda title: find_best_url_match(title, urls_csv))\n",
    "\n",
    "            # Save the modified infos_csv back to a file without 'Unnamed: 0' column\n",
    "            infos_csv.to_csv(infos_file, index=False)\n",
    "        else:\n",
    "            if not os.path.exists(infos_file) and not os.path.exists(urls_file):\n",
    "                # print(f'No both files for {name}')\n",
    "                continue\n",
    "            else:\n",
    "                if not os.path.exists(infos_file):\n",
    "                 print(f'No infos csv for {name}')\n",
    "                if not os.path.exists(urls_file):\n",
    "                    print(f'No url csv for {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
