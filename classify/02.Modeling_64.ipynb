{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress most of the logs\n",
    "# tf.get_logger().setLevel('WARNING')  # Adjust logging level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Category</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product_Info</th>\n",
       "      <th>Product_Feature</th>\n",
       "      <th>Product_Text</th>\n",
       "      <th>Img_URL</th>\n",
       "      <th>Product URL</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Style</th>\n",
       "      <th>RGB_3colors</th>\n",
       "      <th>RGB_percentages</th>\n",
       "      <th>RGB_1st</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Living Room F...</td>\n",
       "      <td>HONBAY Modular Sofa Sleeper Sectional Converti...</td>\n",
       "      <td>$1,299.99</td>\n",
       "      <td>{'Brand': 'HONBAY', 'Assembly Required': 'Yes'...</td>\n",
       "      <td>{'Seating Capacity': '6.00', 'Style': 'Modern'...</td>\n",
       "      <td>Modular Sofa: The modular sectional sofa featu...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/915D-6Yl7s...</td>\n",
       "      <td>https://www.amazon.com/uhome-Upholstered-Sleep...</td>\n",
       "      <td>/home/all/imgs/Sectional_Sofas/HONBAYModularSo...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.83602352 0.82126463 0.78320723]\\n [0.75826...</td>\n",
       "      <td>[18.77 14.85 11.92]</td>\n",
       "      <td>[0.83602352, 0.82126463, 0.78320723]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Living Room F...</td>\n",
       "      <td>CHITA Oversized Modular Sectional Fabric Sofa ...</td>\n",
       "      <td>$1,999.99</td>\n",
       "      <td>{'Brand': 'CHITA', 'Assembly Required': 'Yes',...</td>\n",
       "      <td>{'Seating Capacity': '6', 'Style': 'Modern', '...</td>\n",
       "      <td>6-PIECE U-SHAPED MODULAR SOFA WITH LARGER SEAT...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/811v62pFR9...</td>\n",
       "      <td>https://www.amazon.com/uhome-Upholstered-Sleep...</td>\n",
       "      <td>/home/all/imgs/Sectional_Sofas/CHITAOversizedM...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.85058184 0.83959953 0.81295338]\\n [0.78960...</td>\n",
       "      <td>[24.1  20.6  12.74]</td>\n",
       "      <td>[0.85058184, 0.83959953, 0.81295338]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Living Room F...</td>\n",
       "      <td>HONBAY Modular Sleeper Sofa Bed with Storage S...</td>\n",
       "      <td>$2,599.99</td>\n",
       "      <td>{'Brand': 'HONBAY', 'Seat Depth': '20.5 inches...</td>\n",
       "      <td>{'Seating Capacity': '12.00', 'Style': 'Modern'}</td>\n",
       "      <td>Flexible Combination: Each piece of the modula...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81vOgs7JT9...</td>\n",
       "      <td>https://www.amazon.com/uhome-Upholstered-Sleep...</td>\n",
       "      <td>/home/all/imgs/Sectional_Sofas/HONBAYModularSl...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.04395651 0.04398451 0.04686721]\\n [0.81954...</td>\n",
       "      <td>[21.   17.26 10.71]</td>\n",
       "      <td>[0.04395651, 0.04398451, 0.04686721]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Living Room F...</td>\n",
       "      <td>JUMMICO Convertible Sectional Sofa Couch, L-Sh...</td>\n",
       "      <td>$249.97</td>\n",
       "      <td>{'Brand': 'JUMMICO', 'Assembly Required': 'Yes...</td>\n",
       "      <td>{'Seating Capacity': '3.00', 'Style': 'Modern'...</td>\n",
       "      <td>Comfortable Sectional Couch: Made of modern li...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91pykuT9Sh...</td>\n",
       "      <td>https://www.amazon.com/Legend-Vansen-sectional...</td>\n",
       "      <td>/home/all/imgs/Sectional_Sofas/JUMMICOConverti...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.87697764 0.83760041 0.79600714]\\n [0.12837...</td>\n",
       "      <td>[17.31 15.81 12.8 ]</td>\n",
       "      <td>[0.87697764, 0.83760041, 0.79600714]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Living Room F...</td>\n",
       "      <td>Devion Furniture Contemporary Reversible Secti...</td>\n",
       "      <td>$426.02</td>\n",
       "      <td>{'Brand': 'Devion Furniture', 'Assembly Requir...</td>\n",
       "      <td>{'Seating Capacity': '3', 'Style': 'Contempora...</td>\n",
       "      <td>Finish: Dark Gray Material: Polyester Fabric T...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/718nc67FKP...</td>\n",
       "      <td>https://www.amazon.com/uhome-Upholstered-Sleep...</td>\n",
       "      <td>/home/all/imgs/Sectional_Sofas/DevionFurniture...</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>[[0.8427655  0.84045708 0.85325437]\\n [0.74732...</td>\n",
       "      <td>[17.75 14.62 13.22]</td>\n",
       "      <td>[0.8427655, 0.84045708, 0.85325437]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288</th>\n",
       "      <td>23288</td>\n",
       "      <td>47392</td>\n",
       "      <td>['Office Products', 'Office Furniture &amp; Lighti...</td>\n",
       "      <td>Martin Furniture Storage Credenza, Brown</td>\n",
       "      <td>$961.93</td>\n",
       "      <td>{'Brand': 'Martin Furniture', 'Color': 'Brown'...</td>\n",
       "      <td>{'Material': 'Wood', 'Style': 'French', 'Numbe...</td>\n",
       "      <td>Product Dimensions: 68W x 30H x 18D Ebony fini...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/MEDIAX_792...</td>\n",
       "      <td>https://www.amazon.com/Martin-Furniture-Storag...</td>\n",
       "      <td>/home/all/imgs/Furniture_Sets/MartinFurnitureS...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.12509778 0.11938538 0.11909178]\\n [0.52416...</td>\n",
       "      <td>[24.96 22.46 18.35]</td>\n",
       "      <td>[0.12509778, 0.11938538, 0.11909178]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23289</th>\n",
       "      <td>23289</td>\n",
       "      <td>47393</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Home Office F...</td>\n",
       "      <td>MoNiBloom Modern Desk and Chair Set, 95°-125° ...</td>\n",
       "      <td>Price not Found</td>\n",
       "      <td>{'Color': 'Black', 'Brand': 'MoNiBloom', 'Shap...</td>\n",
       "      <td>{'Style': 'Modern', 'Assembly Required': 'Yes'}</td>\n",
       "      <td>Easy Maintenance - Mesh chairs are very easy f...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/MEDIAX_792...</td>\n",
       "      <td>https://www.amazon.com/MoNiBloom-95%C2%B0-125%...</td>\n",
       "      <td>/home/all/imgs/Furniture_Sets/MoNiBloomModernD...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.17161127 0.16619718 0.16457016]\\n [0.30878...</td>\n",
       "      <td>[17.32 14.4  12.28]</td>\n",
       "      <td>[0.17161127, 0.16619718, 0.16457016]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23290</th>\n",
       "      <td>23290</td>\n",
       "      <td>47395</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Home Office F...</td>\n",
       "      <td>Tribesigns 63 Inch Computer Desk with File Dra...</td>\n",
       "      <td>$159.99</td>\n",
       "      <td>{'Brand': 'Tribesigns', 'Product Dimensions': ...</td>\n",
       "      <td>{'Shape': 'Rectangular', 'Desk design': 'Compu...</td>\n",
       "      <td>[ERGONOMIC DESIGN]: Designed with the elevated...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/MEDIAX_792...</td>\n",
       "      <td>https://www.amazon.com/Tribesigns-Computer-Cab...</td>\n",
       "      <td>/home/all/imgs/Furniture_Sets/TribesignsInchCo...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.84550026 0.82221097 0.79480632]\\n [0.76388...</td>\n",
       "      <td>[36.84 24.95 17.03]</td>\n",
       "      <td>[0.84550026, 0.82221097, 0.79480632]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23291</th>\n",
       "      <td>23291</td>\n",
       "      <td>47396</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Home Office F...</td>\n",
       "      <td>GABRYLLY Ergonomic Mesh Office Chair, High Bac...</td>\n",
       "      <td>$269.50</td>\n",
       "      <td>{'Brand': 'GABRYLLY', 'Color': 'Black', 'Produ...</td>\n",
       "      <td>{'Material': 'Steel, mesh, nylon', 'Item Weigh...</td>\n",
       "      <td>【ERGONOMIC OFFICE CHAIR】- The ergonomic chair ...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/MEDIAX_792...</td>\n",
       "      <td>https://www.amazon.com/Gabrylly-Ergonomic-Mesh...</td>\n",
       "      <td>/home/all/imgs/Furniture_Sets/GABRYLLYErgonomi...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.03004825 0.03003603 0.03031596]\\n [0.11234...</td>\n",
       "      <td>[23.59 18.55 15.32]</td>\n",
       "      <td>[0.03004825, 0.03003603, 0.03031596]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23292</th>\n",
       "      <td>23292</td>\n",
       "      <td>47397</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Home Office F...</td>\n",
       "      <td>Casa Mare 87\" Wood Office Furniture Set of 3pc...</td>\n",
       "      <td>$2,199.00</td>\n",
       "      <td>{'Color': 'White &amp; Brown', 'Brand': 'Casa Mare...</td>\n",
       "      <td>{'Item Weight': '800 Pounds', 'Style': 'Modern...</td>\n",
       "      <td>【OVERALL DIMENSIONS】Right Side L Shaped Office...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/MEDIAX_792...</td>\n",
       "      <td>https://www.amazon.com/Casa-Mare-Executive-Fur...</td>\n",
       "      <td>/home/all/imgs/Furniture_Sets/CasaMareWoodOffi...</td>\n",
       "      <td>Modern</td>\n",
       "      <td>[[0.93128647 0.88644337 0.82613757]\\n [0.84547...</td>\n",
       "      <td>[33.71 16.45 11.93]</td>\n",
       "      <td>[0.93128647, 0.88644337, 0.82613757]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23293 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                 0           0   \n",
       "1                 1           1   \n",
       "2                 2           2   \n",
       "3                 3           3   \n",
       "4                 4           7   \n",
       "...             ...         ...   \n",
       "23288         23288       47392   \n",
       "23289         23289       47393   \n",
       "23290         23290       47395   \n",
       "23291         23291       47396   \n",
       "23292         23292       47397   \n",
       "\n",
       "                                                Category  \\\n",
       "0      ['Home & Kitchen', 'Furniture', 'Living Room F...   \n",
       "1      ['Home & Kitchen', 'Furniture', 'Living Room F...   \n",
       "2      ['Home & Kitchen', 'Furniture', 'Living Room F...   \n",
       "3      ['Home & Kitchen', 'Furniture', 'Living Room F...   \n",
       "4      ['Home & Kitchen', 'Furniture', 'Living Room F...   \n",
       "...                                                  ...   \n",
       "23288  ['Office Products', 'Office Furniture & Lighti...   \n",
       "23289  ['Home & Kitchen', 'Furniture', 'Home Office F...   \n",
       "23290  ['Home & Kitchen', 'Furniture', 'Home Office F...   \n",
       "23291  ['Home & Kitchen', 'Furniture', 'Home Office F...   \n",
       "23292  ['Home & Kitchen', 'Furniture', 'Home Office F...   \n",
       "\n",
       "                                                   Title            Price  \\\n",
       "0      HONBAY Modular Sofa Sleeper Sectional Converti...        $1,299.99   \n",
       "1      CHITA Oversized Modular Sectional Fabric Sofa ...        $1,999.99   \n",
       "2      HONBAY Modular Sleeper Sofa Bed with Storage S...        $2,599.99   \n",
       "3      JUMMICO Convertible Sectional Sofa Couch, L-Sh...          $249.97   \n",
       "4      Devion Furniture Contemporary Reversible Secti...          $426.02   \n",
       "...                                                  ...              ...   \n",
       "23288           Martin Furniture Storage Credenza, Brown          $961.93   \n",
       "23289  MoNiBloom Modern Desk and Chair Set, 95°-125° ...  Price not Found   \n",
       "23290  Tribesigns 63 Inch Computer Desk with File Dra...          $159.99   \n",
       "23291  GABRYLLY Ergonomic Mesh Office Chair, High Bac...          $269.50   \n",
       "23292  Casa Mare 87\" Wood Office Furniture Set of 3pc...        $2,199.00   \n",
       "\n",
       "                                            Product_Info  \\\n",
       "0      {'Brand': 'HONBAY', 'Assembly Required': 'Yes'...   \n",
       "1      {'Brand': 'CHITA', 'Assembly Required': 'Yes',...   \n",
       "2      {'Brand': 'HONBAY', 'Seat Depth': '20.5 inches...   \n",
       "3      {'Brand': 'JUMMICO', 'Assembly Required': 'Yes...   \n",
       "4      {'Brand': 'Devion Furniture', 'Assembly Requir...   \n",
       "...                                                  ...   \n",
       "23288  {'Brand': 'Martin Furniture', 'Color': 'Brown'...   \n",
       "23289  {'Color': 'Black', 'Brand': 'MoNiBloom', 'Shap...   \n",
       "23290  {'Brand': 'Tribesigns', 'Product Dimensions': ...   \n",
       "23291  {'Brand': 'GABRYLLY', 'Color': 'Black', 'Produ...   \n",
       "23292  {'Color': 'White & Brown', 'Brand': 'Casa Mare...   \n",
       "\n",
       "                                         Product_Feature  \\\n",
       "0      {'Seating Capacity': '6.00', 'Style': 'Modern'...   \n",
       "1      {'Seating Capacity': '6', 'Style': 'Modern', '...   \n",
       "2       {'Seating Capacity': '12.00', 'Style': 'Modern'}   \n",
       "3      {'Seating Capacity': '3.00', 'Style': 'Modern'...   \n",
       "4      {'Seating Capacity': '3', 'Style': 'Contempora...   \n",
       "...                                                  ...   \n",
       "23288  {'Material': 'Wood', 'Style': 'French', 'Numbe...   \n",
       "23289    {'Style': 'Modern', 'Assembly Required': 'Yes'}   \n",
       "23290  {'Shape': 'Rectangular', 'Desk design': 'Compu...   \n",
       "23291  {'Material': 'Steel, mesh, nylon', 'Item Weigh...   \n",
       "23292  {'Item Weight': '800 Pounds', 'Style': 'Modern...   \n",
       "\n",
       "                                            Product_Text  \\\n",
       "0      Modular Sofa: The modular sectional sofa featu...   \n",
       "1      6-PIECE U-SHAPED MODULAR SOFA WITH LARGER SEAT...   \n",
       "2      Flexible Combination: Each piece of the modula...   \n",
       "3      Comfortable Sectional Couch: Made of modern li...   \n",
       "4      Finish: Dark Gray Material: Polyester Fabric T...   \n",
       "...                                                  ...   \n",
       "23288  Product Dimensions: 68W x 30H x 18D Ebony fini...   \n",
       "23289  Easy Maintenance - Mesh chairs are very easy f...   \n",
       "23290  [ERGONOMIC DESIGN]: Designed with the elevated...   \n",
       "23291  【ERGONOMIC OFFICE CHAIR】- The ergonomic chair ...   \n",
       "23292  【OVERALL DIMENSIONS】Right Side L Shaped Office...   \n",
       "\n",
       "                                                 Img_URL  \\\n",
       "0      https://m.media-amazon.com/images/I/915D-6Yl7s...   \n",
       "1      https://m.media-amazon.com/images/I/811v62pFR9...   \n",
       "2      https://m.media-amazon.com/images/I/81vOgs7JT9...   \n",
       "3      https://m.media-amazon.com/images/I/91pykuT9Sh...   \n",
       "4      https://m.media-amazon.com/images/I/718nc67FKP...   \n",
       "...                                                  ...   \n",
       "23288  https://m.media-amazon.com/images/W/MEDIAX_792...   \n",
       "23289  https://m.media-amazon.com/images/W/MEDIAX_792...   \n",
       "23290  https://m.media-amazon.com/images/W/MEDIAX_792...   \n",
       "23291  https://m.media-amazon.com/images/W/MEDIAX_792...   \n",
       "23292  https://m.media-amazon.com/images/W/MEDIAX_792...   \n",
       "\n",
       "                                             Product URL  \\\n",
       "0      https://www.amazon.com/uhome-Upholstered-Sleep...   \n",
       "1      https://www.amazon.com/uhome-Upholstered-Sleep...   \n",
       "2      https://www.amazon.com/uhome-Upholstered-Sleep...   \n",
       "3      https://www.amazon.com/Legend-Vansen-sectional...   \n",
       "4      https://www.amazon.com/uhome-Upholstered-Sleep...   \n",
       "...                                                  ...   \n",
       "23288  https://www.amazon.com/Martin-Furniture-Storag...   \n",
       "23289  https://www.amazon.com/MoNiBloom-95%C2%B0-125%...   \n",
       "23290  https://www.amazon.com/Tribesigns-Computer-Cab...   \n",
       "23291  https://www.amazon.com/Gabrylly-Ergonomic-Mesh...   \n",
       "23292  https://www.amazon.com/Casa-Mare-Executive-Fur...   \n",
       "\n",
       "                                                img_path         Style  \\\n",
       "0      /home/all/imgs/Sectional_Sofas/HONBAYModularSo...        Modern   \n",
       "1      /home/all/imgs/Sectional_Sofas/CHITAOversizedM...        Modern   \n",
       "2      /home/all/imgs/Sectional_Sofas/HONBAYModularSl...        Modern   \n",
       "3      /home/all/imgs/Sectional_Sofas/JUMMICOConverti...        Modern   \n",
       "4      /home/all/imgs/Sectional_Sofas/DevionFurniture...  Contemporary   \n",
       "...                                                  ...           ...   \n",
       "23288  /home/all/imgs/Furniture_Sets/MartinFurnitureS...        Modern   \n",
       "23289  /home/all/imgs/Furniture_Sets/MoNiBloomModernD...        Modern   \n",
       "23290  /home/all/imgs/Furniture_Sets/TribesignsInchCo...        Modern   \n",
       "23291  /home/all/imgs/Furniture_Sets/GABRYLLYErgonomi...        Modern   \n",
       "23292  /home/all/imgs/Furniture_Sets/CasaMareWoodOffi...        Modern   \n",
       "\n",
       "                                             RGB_3colors      RGB_percentages  \\\n",
       "0      [[0.83602352 0.82126463 0.78320723]\\n [0.75826...  [18.77 14.85 11.92]   \n",
       "1      [[0.85058184 0.83959953 0.81295338]\\n [0.78960...  [24.1  20.6  12.74]   \n",
       "2      [[0.04395651 0.04398451 0.04686721]\\n [0.81954...  [21.   17.26 10.71]   \n",
       "3      [[0.87697764 0.83760041 0.79600714]\\n [0.12837...  [17.31 15.81 12.8 ]   \n",
       "4      [[0.8427655  0.84045708 0.85325437]\\n [0.74732...  [17.75 14.62 13.22]   \n",
       "...                                                  ...                  ...   \n",
       "23288  [[0.12509778 0.11938538 0.11909178]\\n [0.52416...  [24.96 22.46 18.35]   \n",
       "23289  [[0.17161127 0.16619718 0.16457016]\\n [0.30878...  [17.32 14.4  12.28]   \n",
       "23290  [[0.84550026 0.82221097 0.79480632]\\n [0.76388...  [36.84 24.95 17.03]   \n",
       "23291  [[0.03004825 0.03003603 0.03031596]\\n [0.11234...  [23.59 18.55 15.32]   \n",
       "23292  [[0.93128647 0.88644337 0.82613757]\\n [0.84547...  [33.71 16.45 11.93]   \n",
       "\n",
       "                                    RGB_1st  cluster_label  \n",
       "0      [0.83602352, 0.82126463, 0.78320723]              0  \n",
       "1      [0.85058184, 0.83959953, 0.81295338]              0  \n",
       "2      [0.04395651, 0.04398451, 0.04686721]              5  \n",
       "3      [0.87697764, 0.83760041, 0.79600714]              0  \n",
       "4       [0.8427655, 0.84045708, 0.85325437]              0  \n",
       "...                                     ...            ...  \n",
       "23288  [0.12509778, 0.11938538, 0.11909178]              5  \n",
       "23289  [0.17161127, 0.16619718, 0.16457016]              1  \n",
       "23290  [0.84550026, 0.82221097, 0.79480632]              0  \n",
       "23291  [0.03004825, 0.03003603, 0.03031596]              5  \n",
       "23292  [0.93128647, 0.88644337, 0.82613757]              0  \n",
       "\n",
       "[23293 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\BigF\\\\team5\\\\classify\\\\combined_product_infos_with_colors_final.csv')\n",
    "# X = np.load('images64.npy')\n",
    "# y = np.load('styles64.npy')\n",
    "# X and y are now numpy arrays containing your data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23343, 23343, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(X), type(y), type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Classic', 'Contemporary', 'Country', 'Minimalism', 'Modern',\n",
       "        'Unique', 'Urban'], dtype='<U12'),\n",
       " array([ 2668,  1631,  1157,   190, 16642,    70,   985]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Classic', 'Contemporary', 'Country', 'Minimalism', 'Modern',\n",
      "       'Urban'], dtype='<U12'), array([2668, 1631, 1157,  190, 2500,  985]))\n"
     ]
    }
   ],
   "source": [
    "# 모던 줄이기\n",
    "# 줄이고자 하는 값과 그 개수 설정\n",
    "value_to_reduce = 'Modern'\n",
    "desired_count = 2500\n",
    "\n",
    "# 값의 인덱스 찾기\n",
    "indices = np.where(y == value_to_reduce)[0]\n",
    "\n",
    "# 원하는 개수 이상의 인덱스 제거\n",
    "if len(indices) > desired_count:\n",
    "    indices_to_remove = indices[desired_count:]\n",
    "    tempy = np.delete(y, indices_to_remove)\n",
    "    tempX = np.delete(X, indices_to_remove, axis=0)\n",
    "np.unique(tempy, return_counts=True)\n",
    "\n",
    "# 유니크 삭제\n",
    "indices_to_remove = np.where(tempy == 'Unique')[0]\n",
    "\n",
    "# 'Modern' 값을 가진 인덱스를 y 배열에서 제거\n",
    "tempy2 = np.delete(tempy, indices_to_remove)\n",
    "# 동일한 인덱스를 X 배열에서 제거 (X가 2차원 배열일 경우 axis=0)\n",
    "rX = np.delete(tempX, indices_to_remove, axis=0)\n",
    "\n",
    "# 결과 확인\n",
    "print(np.unique(tempy2, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ry = np.where(tempy2 == 'Minimalism', 'Contemporary', tempy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Classic', 'Contemporary', 'Country', 'Modern', 'Urban'],\n",
      "      dtype='<U12'), array([2668, 1821, 1157, 2500,  985]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9131,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(ry, return_counts=True))\n",
    "ry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_r.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "le = LabelEncoder()\n",
    "ley = le.fit_transform(ry)\n",
    "\n",
    "# Save the LabelEncoder\n",
    "joblib.dump(le, 'label_encoder_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([2668, 1821, 1157, 2500,  985]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9131, (9131,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(ley, return_counts=True))\n",
    "len(ley), ley.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9131, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming y contains integer labels\n",
    "cay = to_categorical(ry, num_classes=5)\n",
    "cay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([2668, 1821, 1157, 2500,  985]))\n",
      "(array(['Classic', 'Contemporary', 'Country', 'Modern', 'Urban'],\n",
      "      dtype='<U12'), array([2668, 1821, 1157, 2500,  985]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9131,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(ley, return_counts=True))\n",
    "print(np.unique(ry, return_counts=True))\n",
    "ley.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Now proceed with the train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(rX, ry, test_size=0.15, random_state=1, stratify=ry)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7761, 64, 64, 3) (685, 64, 64, 3) (685, 64, 64, 3)\n",
      "(7761,) (685,) (685,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Conv2D, AvgPool2D, Flatten, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        1568      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 16, 16, 32)        0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 16)        8208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 4, 4, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 8)           2056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 4, 4, 8)           32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 8)           0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 15:46:48.812502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-07 15:46:48.843884: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 1, 1, 8)           0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1152      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14365 (56.11 KB)\n",
      "Trainable params: 13997 (54.68 KB)\n",
      "Non-trainable params: 368 (1.44 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_DNN = Sequential([\n",
    "    Input(X_train.shape[1:]),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Conv2D(filters=16, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Conv2D(filters=8, kernel_size=(4,4), strides=(1,1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    AvgPool2D(pool_size=(4,4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(5),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "                            #    monitor='val_loss',\n",
    "                               monitor='val_accuracy',\n",
    "                               patience=15,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=15,\n",
    "                              verbose=1,\n",
    "                              min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "start fitting\n",
      "Epoch 1/10000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum GPUs Available: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart fitting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_DNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitting done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filesgn2qhwl.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/hwang/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model_DNN.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('start fitting')\n",
    "history = model_DNN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10000000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print('fitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 9ms/step\n",
      "[1.7875820e-01 1.1644329e-01 9.1719755e-04 7.0386475e-01 1.6576321e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 1, 3, 1, 0, 3, 4, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_DNN.predict(X_test)\n",
    "print(y_pred[0])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6934306569343066\n",
      "Confusion Matrix:\n",
      " [[165   6   6   8  15]\n",
      " [ 33  62  10  22  10]\n",
      " [ 19   4  54   0  10]\n",
      " [ 19  21   1 143   3]\n",
      " [ 17   0   6   0  51]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.73       200\n",
      "           1       0.67      0.45      0.54       137\n",
      "           2       0.70      0.62      0.66        87\n",
      "           3       0.83      0.76      0.79       187\n",
      "           4       0.57      0.69      0.63        74\n",
      "\n",
      "    accuracy                           0.69       685\n",
      "   macro avg       0.68      0.67      0.67       685\n",
      "weighted avg       0.70      0.69      0.69       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if y_test.ndim > 1:  # Check if y_test is one-hot encoded\n",
    "    y_test_int_labels = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_int_labels = y_test  # y_test is already in integer label format\n",
    "\n",
    "# Now calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_int_labels, y_pred_labels))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_int_labels, y_pred_labels))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_int_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwang/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_DNN.save('./DNN/DNN2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8217, 12288) (914, 12288)\n",
      "(8217,) (914,)\n"
     ]
    }
   ],
   "source": [
    "# Reshape X from (len(X), 64, 64, 3) to (len(X), 1, 12288)\n",
    "rX_ml = rX.reshape(len(rX),-1)  # -1 tells numpy to infer the dimension\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Now proceed with the train_test_split\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(rX_ml, ley, test_size=0.1, random_state=1, stratify=ley)\n",
    "\n",
    "print(X_train_ml.shape, X_test_ml.shape)\n",
    "print(y_train_ml.shape, y_test_ml.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.73%\n",
      "Precision: 0.83\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n",
      "Confusion Matrix:\n",
      "[[224  11   5  27   0]\n",
      " [ 23 139   2  16   2]\n",
      " [ 20   8  80   8   0]\n",
      " [ 13  13   0 224   0]\n",
      " [ 11   4   0   4  80]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predictions\n",
    "y_pred_RFC = RFC.predict(X_test_ml)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_RFC = accuracy_score(y_test_ml, y_pred_RFC)\n",
    "print(f\"Accuracy: {accuracy_RFC * 100:.2f} %\")\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision_RFC = precision_score(y_test_ml, y_pred_RFC, average='weighted')\n",
    "recall_RFC = recall_score(y_test_ml, y_pred_RFC, average='weighted')\n",
    "f1_RFC = f1_score(y_test_ml, y_pred_RFC, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision_RFC:.2f} %\")\n",
    "print(f\"Recall: {recall_RFC:.2f} %\")\n",
    "print(f\"F1 Score: {f1_RFC:.2f} %\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_RFC = confusion_matrix(y_test_ml, y_pred_RFC)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_RFC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./ML/RFC2.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# # Load the model from the file\n",
    "# SVM_model = joblib.load('svm_model.joblib')\n",
    "print(RFC)\n",
    "joblib.dump(RFC, './ML/RFC2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.39%\n",
      "Precision: 0.83\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n",
      "Confusion Matrix:\n",
      "[[224  14   4  24   1]\n",
      " [ 23 141   1  15   2]\n",
      " [ 18  10  80   8   0]\n",
      " [ 14   9   0 227   0]\n",
      " [  6   7   1   4  81]]\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "SVM = SVC()\n",
    "\n",
    "# Random Forest\n",
    "SVM = RandomForestClassifier()\n",
    "SVM.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predictions\n",
    "y_pred_SVM = SVM.predict(X_test_ml)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_SVM = accuracy_score(y_test_ml, y_pred_SVM)\n",
    "print(f\"Accuracy: {accuracy_SVM * 100:.2f} %\")\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision_SVM = precision_score(y_test_ml, y_pred_SVM, average='weighted')\n",
    "recall_SVM = recall_score(y_test_ml, y_pred_SVM, average='weighted')\n",
    "f1_SVM = f1_score(y_test_ml, y_pred_SVM, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision_SVM:.2f} %\")\n",
    "print(f\"Recall: {recall_SVM:.2f} %\")\n",
    "print(f\"F1 Score: {f1_SVM:.2f} %\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_SVM = confusion_matrix(y_test_ml, y_pred_SVM)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_SVM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "# Assuming your SVM model is named as SVM\n",
    "joblib.dump(SVM, './ML/SVM2.joblib')\n",
    "print(SVM)\n",
    "# # Load the model from the file\n",
    "# SVM_model = joblib.load('svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.84%\n",
      "Precision: 0.82\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n",
      "Confusion Matrix:\n",
      "[[222  16   6  23   0]\n",
      " [ 15 144   2  19   2]\n",
      " [ 20   7  80   7   2]\n",
      " [ 16  10   0 224   0]\n",
      " [ 12   7   1   1  78]]\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "XGB= xgb.XGBClassifier()\n",
    "XGB.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predictions\n",
    "y_pred_XGB = XGB.predict(X_test_ml)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_XGB = accuracy_score(y_test_ml, y_pred_XGB)\n",
    "print(f\"Accuracy: {accuracy_XGB * 100:.2f}%\")\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision_XGB = precision_score(y_test_ml, y_pred_XGB, average='weighted')\n",
    "recall_XGB = recall_score(y_test_ml, y_pred_XGB, average='weighted')\n",
    "f1_XGB = f1_score(y_test_ml, y_pred_XGB, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision_XGB:.2f}\")\n",
    "print(f\"Recall: {recall_XGB:.2f}\")\n",
    "print(f\"F1 Score: {f1_XGB:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_XGB = confusion_matrix(y_test_ml, y_pred_XGB)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_XGB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n"
     ]
    }
   ],
   "source": [
    "# Assuming your SVM model is named as SVM\n",
    "joblib.dump(XGB, './ML/XGB2.joblib')\n",
    "print(XGB)\n",
    "# # Load the model from the file\n",
    "# SVM_model = joblib.load('svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.76%\n",
      "Precision: 0.40\n",
      "Recall: 0.37\n",
      "F1 Score: 0.35\n",
      "Confusion Matrix:\n",
      "[[ 55  49  23  74  66]\n",
      " [ 22  38   7  64  51]\n",
      " [  8  12  19  37  40]\n",
      " [ 11  28   6 178  27]\n",
      " [  5  12   5  31  46]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "GNB= GaussianNB()\n",
    "\n",
    "GNB.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predictions\n",
    "y_pred_GNB = GNB.predict(X_test_ml)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_GNB = accuracy_score(y_test_ml, y_pred_GNB)\n",
    "print(f\"Accuracy: {accuracy_GNB * 100:.2f}%\")\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision_GNB = precision_score(y_test_ml, y_pred_GNB, average='weighted')\n",
    "recall_GNB = recall_score(y_test_ml, y_pred_GNB, average='weighted')\n",
    "f1_GNB = f1_score(y_test_ml, y_pred_GNB, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision_GNB:.2f}\")\n",
    "print(f\"Recall: {recall_GNB:.2f}\")\n",
    "print(f\"F1 Score: {f1_GNB:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_GNB = confusion_matrix(y_test_ml, y_pred_GNB)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_GNB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(GNB, './ML/GNB.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
